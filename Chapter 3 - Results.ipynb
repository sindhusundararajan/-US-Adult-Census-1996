{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Summary\n",
    "We now use the best models derived in Chapter 2 and assess them against the test data.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# preprocessing function - developped in Chapter 1\n",
    "the_columns  = [('age', 'continuous'), \n",
    "                ('class_of_worker', 'nominal'), \n",
    "                ('detailed_industry_code', 'nominal'), \n",
    "                ('detailed_occupation_code', 'nominal'), \n",
    "                ('education', 'nominal'), \n",
    "                ('wage_per_hour', 'continuous'), \n",
    "                ('enrolled_in_edu_last_week', 'nominal'),\n",
    "                ('marital_status', 'nominal'),\n",
    "                ('major_industry_code', 'nominal'),\n",
    "                ('major_occupation_code', 'nominal'),\n",
    "                ('race', 'nominal'),\n",
    "                ('hispanic_origin', 'nominal'),\n",
    "                ('sex', 'binary'), # binary column with values Male/Female\n",
    "                ('member_of_labor_union', 'nominal'), \n",
    "                ('reason_for_unemployment', 'nominal'),\n",
    "                ('full_or_part_time_employment_stat', 'nominal'),\n",
    "                ('capital_gains', 'continuous'),\n",
    "                ('capital_losses', 'continuous'),\n",
    "                ('dividends', 'continuous'),\n",
    "                ('tax_filer', 'nominal'),\n",
    "                ('region_of_previous_residence', 'nominal'),\n",
    "                ('state_of_previous_residence', 'nominal'),\n",
    "                ('detailed_household_family_stat', 'nominal'),\n",
    "                ('detailed_household_summary', 'nominal'),\n",
    "                ('instance_weight', 'IGNORE'), # as per instructions, to be dropped\n",
    "                ('migration_code_change_in_msa', 'nominal'),\n",
    "                ('migration_code_change_in_reg', 'nominal'),\n",
    "                ('migration_code_move_within_reg', 'nominal'),\n",
    "                ('live_in_this_house_1_yr_ago', 'nominal'),\n",
    "                ('migration_prev_res_in_sunbelt', 'nominal'),\n",
    "                ('num_persons_worked_for_employer', 'continuous'),\n",
    "                ('family_members_under_18', 'nominal'),\n",
    "                ('cob_father', 'nominal'),\n",
    "                ('cob_mother', 'nominal'),\n",
    "                ('cob_self', 'nominal'),\n",
    "                ('citizenship', 'nominal'),\n",
    "                ('own_business_or_self_employed', 'nominal'),\n",
    "                ('fill_in_questionnaire_for_veterans_admin', 'nominal'),\n",
    "                ('veterans_benefits', 'nominal'),\n",
    "                ('weeks_worked_in_year', 'nominal'),\n",
    "                ('year', 'nominal'), \n",
    "                ('savings','target')] # binary TARGET variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocessData(file_name):\n",
    "    # the_columns stores tuples of (column_name and tag for continuous/nominal/binary/target)\n",
    "    \n",
    "    raw_data = pd.read_csv(file_name, names=[c[0] for c in the_columns], index_col=False)\n",
    "    original_shape = raw_data.shape\n",
    "    \n",
    "    raw_data.drop('instance_weight', axis=1, inplace=True)\n",
    "    #the_columns.remove(('instance_weight', 'IGNORE'))\n",
    "    \n",
    "    # find the duplicate rows, keep the first one\n",
    "    duplicate_rows = raw_data.duplicated(keep='first')\n",
    "    \n",
    "    print 'number of duplicates = {:d}'.format(duplicate_rows.sum())\n",
    "    raw_data = raw_data.drop_duplicates(keep='first')\n",
    "    new_shape =  raw_data.shape\n",
    "    print 'number of duplicates removed = {:d}'.format(original_shape[0] - new_shape[0])\n",
    "    print 'original shape = {:d}, {:d}'.format(original_shape[0], original_shape[1])\n",
    "    print 'new shape = {:d}, {:d}'.format(raw_data.shape[0], raw_data.shape[1])\n",
    "    \n",
    "    # convert nominal columns (object dtype) to integer type\n",
    "    data = pd.DataFrame(raw_data.select_dtypes(include=['object']))\n",
    "    object_columns = data.columns\n",
    "    \n",
    "    for column in object_columns:\n",
    "        unique_values = data[column].unique()\n",
    "        dictionary = {key:idx for idx,key in enumerate(unique_values)}\n",
    "        data[column] = data[column].apply(lambda x : dictionary[x])\n",
    "    \n",
    "    # add nominal columns that were already in integer format \n",
    "    nominal_integer_columns = [c[0] for c in the_columns \n",
    "                               if c[1] == 'nominal' and c[0] not in data.columns]\n",
    "    data[nominal_integer_columns] = raw_data[nominal_integer_columns]\n",
    "    \n",
    "    # convert 'sex', and 'savings' columns to binary; add year column\n",
    "    data['savings'] = raw_data['savings'].map(lambda x: \n",
    "                                              1 if str(x).strip() == '50000+.' else 0)\n",
    "    data['sex'] = raw_data['sex'].map(lambda x: \n",
    "                                      1 if str(x).strip() == 'Male' else 0)\n",
    "    data['year'] = raw_data['year']\n",
    "    \n",
    "    # add continuous columns\n",
    "    continuous_columns = [c[0] for c in the_columns if c[1] == 'continuous']\n",
    "    data[continuous_columns] = raw_data[continuous_columns]\n",
    "    \n",
    "    # verify that we aren't missing any columns\n",
    "    assert set(data.columns) == (set(raw_data.columns))\n",
    "    \n",
    "    text = 'The final processed data has {:,d} rows and {:d} columns.\\n'\n",
    "    print text.format(data.shape[0], data.shape[1])\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of duplicates = 46627\n",
      "number of duplicates removed = 46627\n",
      "original shape = 199523, 42\n",
      "new shape = 152896, 41\n",
      "The final processed data has 152,896 rows and 41 columns.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data = preprocessData('us_census_full/census_income_learn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of duplicates = 20898\n",
      "number of duplicates removed = 20898\n",
      "original shape = 99762, 42\n",
      "new shape = 78864, 41\n",
      "The final processed data has 78,864 rows and 41 columns.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_data = preprocessData('us_census_full/census_income_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Imbalance\n",
    "We found in Chapter 1 that the training data exhibits some degree of class imbalance where 91.2% of persons had savings less than 50K. The test set has approximately the same degree of class imbalance, calculated below at 91.5%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Records with savings > 50K:    6,186\n",
      "Records with savings < 50K:   72,678\n",
      "The class imbalance is 91.4885% or approximately 11 to 1.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n = test_data[test_data['savings'] == 1]['savings'].count()\n",
    "m = test_data[test_data['savings'] == 0]['savings'].count()\n",
    "imbalance = (1.0 - float(n)/m)*100\n",
    "print '\\nRecords with savings > 50K: {:8,d}'.format(n)\n",
    "print 'Records with savings < 50K: {:8,d}'.format(m)\n",
    "print 'The class imbalance is {:.4f}% or approximately {:d} to 1.\\n'.format(imbalance, m/n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_confusion_matrix(y_true, y_pred):\n",
    "    header = '\\t          prediction 0    prediction 1'\n",
    "    row0 =   '\\tclass 0 {:11,d} {:14,d}'\n",
    "    row1 =   '\\tclass 1 {:11,d} {:14,d}'\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print header\n",
    "    print row0.format(cm[0,0], cm[0,1])\n",
    "    print row1.format(cm[1,0], cm[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t          prediction 0    prediction 1\n",
      "\tclass 0      72,678              0\n",
      "\tclass 1           0          6,186\n"
     ]
    }
   ],
   "source": [
    "print_confusion_matrix(test_data.loc[:,'savings'], test_data.loc[:,'savings'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = train_data.drop('savings', axis=1)\n",
    "y_train = train_data.loc[:,'savings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = test_data.drop('savings', axis=1)\n",
    "y_test = test_data.loc[:,'savings']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Best Random Forest Scored by Accuracy\n",
    "\n",
    "best_features_for_accuracy = {'max_features': 'sqrt', \n",
    "                              'min_samples_split': 2, \n",
    "                              'n_estimators': 200, \n",
    "                              'max_depth': None, \n",
    "                              'class_weight': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "\t          prediction 0    prediction 1\n",
      "\tclass 0      72,449            229\n",
      "\tclass 1       4,907          1,279\n",
      "\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.93657   0.99685   0.96577     72678\n",
      "          1    0.84814   0.20676   0.33247      6186\n",
      "\n",
      "avg / total    0.92963   0.93488   0.91609     78864\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_acc = RandomForestClassifier(max_features='sqrt',\n",
    "                                min_samples_split=2, \n",
    "                                n_estimators=200, \n",
    "                                max_depth=None, \n",
    "                                class_weight=None, \n",
    "                                n_jobs=2)\n",
    "\n",
    "rf_acc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf_acc.predict(X_test)\n",
    "\n",
    "print 'Confusion matrix:'\n",
    "print_confusion_matrix(y_test, y_pred)\n",
    "print '\\nClassification report:'\n",
    "print classification_report(y_test, y_pred, digits=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Best Random Forest Scored By Precision\n",
    "\n",
    "best_features_for_precision = {'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 200, 'max_depth': 6, 'class_weight': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "\t          prediction 0    prediction 1\n",
      "\tclass 0      72,631             47\n",
      "\tclass 1       5,611            575\n",
      "\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.92829   0.99935   0.96251     72678\n",
      "          1    0.92444   0.09295   0.16892      6186\n",
      "\n",
      "avg / total    0.92798   0.92826   0.90026     78864\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_pre = RandomForestClassifier(max_features='sqrt',\n",
    "                                min_samples_split=2, \n",
    "                                n_estimators=200, \n",
    "                                max_depth=6, \n",
    "                                class_weight=None, \n",
    "                                n_jobs=2)\n",
    "\n",
    "rf_pre.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf_pre.predict(X_test)\n",
    "\n",
    "print 'Confusion matrix:'\n",
    "print_confusion_matrix(y_test, y_pred)\n",
    "print '\\nClassification report:'\n",
    "print classification_report(y_test, y_pred, digits=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Random Forest Scored By Recall\n",
    "\n",
    "best_features_for_recall = {'max_features': 40, 'min_samples_split': 2, 'n_estimators': 200, 'max_depth': 6, 'class_weight': {1: 5}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "\t          prediction 0    prediction 1\n",
      "\tclass 0      66,540          6,138\n",
      "\tclass 1       1,899          4,287\n",
      "\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.97225   0.91555   0.94305     72678\n",
      "          1    0.41122   0.69302   0.51616      6186\n",
      "\n",
      "avg / total    0.92825   0.89809   0.90956     78864\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_rec = RandomForestClassifier(max_features=40,\n",
    "                                min_samples_split=2, \n",
    "                                n_estimators=200, \n",
    "                                max_depth=6, \n",
    "                                class_weight={1:5}, \n",
    "                                n_jobs=2)\n",
    "\n",
    "rf_rec.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf_rec.predict(X_test)\n",
    "\n",
    "print 'Confusion matrix:'\n",
    "print_confusion_matrix(y_test, y_pred)\n",
    "print '\\nClassification report:'\n",
    "print classification_report(y_test, y_pred, digits=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest and Under-Sampling\n",
    "\n",
    "The best parameters are:\n",
    "#{'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 200, 'max_depth': 6, 'class_weight': {1: 5}}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "\t          prediction 0    prediction 1\n",
      "\tclass 0      31,265         41,413\n",
      "\tclass 1         110          6,076\n",
      "\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.99649   0.43019   0.60094     72678\n",
      "          1    0.12795   0.98222   0.22640      6186\n",
      "\n",
      "avg / total    0.92837   0.47349   0.57156     78864\n",
      "\n"
     ]
    }
   ],
   "source": [
    "under_sample = RandomUnderSampler()\n",
    "imb_x, imb_y = under_sample.fit_sample(X_train, y_train)\n",
    "\n",
    "rf_us = RandomForestClassifier(max_features='sqrt',\n",
    "                               min_samples_split=2, \n",
    "                               n_estimators=200, \n",
    "                               max_depth=6, \n",
    "                               class_weight={1:5}, \n",
    "                               n_jobs=2)\n",
    "\n",
    "rf_us.fit(imb_x, imb_y)\n",
    "\n",
    "y_pred = rf_us.predict(X_test)\n",
    "\n",
    "print 'Confusion matrix:'\n",
    "print_confusion_matrix(y_test, y_pred)\n",
    "print '\\nClassification report:'\n",
    "print classification_report(y_test, y_pred, digits=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest and Tomek-Links\n",
    "\n",
    "best parameters = \n",
    "{'max_features': 40, 'min_samples_split': 2, 'n_estimators': 200, 'max_depth': 6, 'class_weight': {1: 5}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "\t          prediction 0    prediction 1\n",
      "\tclass 0      66,331          6,347\n",
      "\tclass 1       1,855          4,331\n",
      "\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.97280   0.91267   0.94177     72678\n",
      "          1    0.40560   0.70013   0.51364      6186\n",
      "\n",
      "avg / total    0.92830   0.89600   0.90819     78864\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tlk = TomekLinks()\n",
    "\n",
    "tlk_x, tlk_y = tlk.fit_sample(X_train, y_train)\n",
    "\n",
    "rf_tlk = RandomForestClassifier(n_estimators = 200, max_depth=6, \n",
    "                                max_features=40, min_samples_split=2, \n",
    "                                class_weight={1:5}, n_jobs=2)\n",
    "\n",
    "rf_tlk.fit(tlk_x, tlk_y)\n",
    "\n",
    "y_pred = rf_tlk.predict(X_test)\n",
    "\n",
    "print 'Confusion matrix:'\n",
    "print_confusion_matrix(y_test, y_pred)\n",
    "print '\\nClassification report:'\n",
    "print classification_report(y_test, y_pred, digits=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest and Over-Sampling\n",
    "\n",
    "best parameters = \n",
    "'max_features': 40, 'min_samples_split': 2, 'n_estimators': 200, 'max_depth': None, 'class_weight': None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "\t          prediction 0    prediction 1\n",
      "\tclass 0      71,912            766\n",
      "\tclass 1       4,622          1,564\n",
      "\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.93961   0.98946   0.96389     72678\n",
      "          1    0.67124   0.25283   0.36731      6186\n",
      "\n",
      "avg / total    0.91856   0.93168   0.91710     78864\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ros = RandomOverSampler()\n",
    "ros_x, ros_y = ros.fit_sample(X_train, y_train)\n",
    "\n",
    "rf_os = RandomForestClassifier(n_estimators = 200, max_depth=None, \n",
    "                               max_features=40, min_samples_split=2,\n",
    "                               class_weight=None, n_jobs=2)\n",
    "\n",
    "rf_os.fit(ros_x, ros_y)\n",
    "\n",
    "y_pred = rf_os.predict(X_test)\n",
    "\n",
    "print 'Confusion matrix:'\n",
    "print_confusion_matrix(y_test, y_pred)\n",
    "print '\\nClassification report:'\n",
    "print classification_report(y_test, y_pred, digits=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
